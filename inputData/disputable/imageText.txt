
In the theory of law, a controversy differs from a legal case; while legal cases include all suits, criminal as well as civil, a controversy is a purely civil proceeding

For example, the Case or Controversy Clause of Article Three of the United States Constitution (Section 2, Clause 1) states that "the judicial Power shall extend ... to
Controversies to which the United States shall be a Party". This clause has been deemed to impose a requirement that United States federal courts are not permitted to
cases that do not pose an actual controversy—that is, an actual dispute between adverse parties which is capable of being resolved by the [court]. In addition to setting
out the scope of the jurisdiction of the federal judiciary, it also prohibits courts from issuing advisory opinions, or from hearing cases that are either unripe, meaning that
the controversy has not arisen yet, or moot, meaning that the controversy has already been resolved
Benford's law
Main article: Benfora's law of controversy

Benford! law of controversy, as expressed by the astrophysicist and science fiction author Gregory Benford in 1980, states: Passion is inversely proportional to the
amount of real information available.\""] in other words, it claims that the less factual information is available on a topic, the more controversy can arise around that topic
—and the more facts are available, the less controversy can arise. Thus, for example, controversies in physics would be limited to subject areas where experiments
cannot be carried out yet, whereas controversies would be inherent to politics, where communities must frequently decide on courses of action based on insufficient,
information.
Psychological bases

Controversies are frequently thought to be a result of a lack of confidence on the part of the disputants — as implied by Benford's law of controversy, which only talks
about lack of information ("passion is inversely proportional to the amount of real information available"). For example, in analyses of the political controversy over
anthropogenic climate change, which is exceptionally virulent in the United States, it has been proposed that those who are opposed to the scientific consensus do so
because they don't have enough information about the topic."!41 4 study of 1540 US adults! found instead that levels of scientific literacy correlated with the strength of
opinion on climate change, but not on which side of the debate that they stood

The puzzling phenomenon of two individuals being able to reach different conclusions after being exposed to the same facts has been frequently explained (particularly
by Daniel Kahneman) by reference to a 'bounded rationality' — in other words, that most judgments are made using fast acting heuristics”! that work well in every day
situations, but are not amenable to decision-making about complex subjects such as climate change. Anchoring has been particularly identified as relevant in climate
change controversies !! as individuals are found to be more positively inclined to believe in climate change if the outside temperature is higher, if they have been primed
to think about heat, and if they are primed with higher temperatures when thinking about the future temperature increases from climate change.

In other controversies — such as that around the HPV vaccine, the same evidence seemed to license inference to radically different conclusions." Kahan et al.{")
explained this by the cognitive biases of biased assimilation!" and a credibility heuristic.!"71

Similar effects on reasoning are also seen in non-scientific controversies, for example in the gun control debate in the United States.{"3) As with other controversies, it
has been suggested that exposure to empirical facts would be sufficient to resolve the debate once and for all.!"4I!"5] jn computer simulations of cultural communities,
beliefs were found to polarize within isolated sub-groups, based on the mistaken belief of the community's unhindered access to ground truth.!"3) Such confidence in the
group to find the ground truth is explicable through the success of wisdom of the crowd based inferences.|"®] However, if there is no access to the ground truth, as there
was not in this model, the method will fil

Bayesian decision theory allows these failures of rationality to be described as part of a statistically optimized system for decision making. Experiments and
computational models in multisensory integration have shown that sensory input from different senses is integrated in a statistically optimal way,!""! in addition, it appears
that the kind of inferences used to infer single sources for multiple sensory inputs uses a Bayesian inference about the causal origin of the sensory stimuti!"8] As such, it
appears neurobiologically plausible that the brain implements decision-making procedures that are close to optimal for Bayesian inference

Brocas and Carrillo propose a model to make decisions based on noisy sensory inputs,!"! beliefs about the state of the world are modified by Bayesian updating, and
then decisions are made based on beliefs passing a threshold. They show that this model, when optimized for single-step decision making, produces belief anchoring
and polarization of opinions — exactly as described in the global warming controversy context — in spite of identical evidence presented, the pre-existing beliefs (or
evidence presented first) has an overwhelming effect on the beliefs formed. In addition, the preferences of the agent (the particular rewards that they value) also cause
the beliefs formed to change — this explains the biased assimilation (also known as confirmation bias) shown above. This model allows the production of controversy to
be seen as a consequence of a decision maker optimized for single-step decision making, rather than as a result of limited reasoning in the bounded rationality of Daniel
Kahneman
References

1. * "EFF Quotes Collection 19.6" 2. Electronic Frontier Foundation. 2001-04-09.
‘Archived from the original ? on 2007-09-29. Retrieved 2016-12-04.

2. § "Quotations: Computer Laws" ct. SysProg. Archived from the original cz on
2008-08-22. Retrieved 2007-03-10

3. * Ungar, S. (2000). "Knowledge, ignorance and the popular culture: climate change
versus the ozone hole”. Public Understanding of Science. 9 (3): 297-312
doi:10.1088/0963-6625/9/3/306 :7. S2CID 7089937 «2

4. 4 Pidgeon, N.; B. Fischhoff (2011). "The role of social and decision sciences in
communicating uncertain climate risks". Nature Climate Change. 1 (1): 35-41
Bibcode:2011NatCC...1..35P c2. doi:10.1038/nclimate1080 c2. S2CID 85362091 cz

5. * Kahan, Dan M.; Maggie Wittlin; Ellen Peters; Paul Slovic; Lisa Larrimore
Ouellette; Donald Braman; Gregory N. Mandel (2011). "The Tragedy of the Risk-
Perception Commons: Culture Conflict, Rationality Conflict, and Climate Change”
hal:1794/22097 3. SSRN 18715032

6. * Kahneman, Daniel (2003-12-01). "Maps of Bounded Rationality: Psychology
for Behavioral Economics” fa (PDF). The American Economic Review. 93 (5):
1449-1475. CiteSeerX 10.1.1.194.6564 g. doi:10.1257/000282803322655392 2
ISSN 0002-8282... JSTOR 3132137 w. Archived from the original (PDF) on
2018-02-19. Retrieved 2017-10-24.

7. Twersky, A.; D. Kahneman (1974). "Judgment under uncertainty: Heuristics and
biases’ 2. Science. 185 (4167): 1124-31. Bibcode:1974Sci...185.124T 2
doi:10.1126/science. 185.4157.1124.z. PMID 17835457 . S2CID 143452957
Archived cz from the original on 2018-06-01. Retrieved 2017-08-30.

8. * Joireman, Jeff; Heather Barnes Truelove; Blythe Duell (December 2010). "Effect of
outdoor temperature, heat primes and anchoring on belief in global warming’
Joumal of Environmental Psychology. 30 (4): 358-367.
doi:10.1016/jerwp.2010.03.004 . ISSN 0272-4944

9. * Saul, Stephanie; Andrew Pollack (2007-02-17). "Furor on Rush to Require
Conical Cancer Vaccine”. The New York Times. ISSN 0362-4331 7. Retrieved
2011-11-26
10.

1"

2

B

14,

5

16

17.

8

19

* Kahan, Dan M.; Donald Braman: Geoffrey L. Cohen: Paul Slovic; John Gastil
(2008-07-15). "Who Fears the HPV Vaccine, Who Doesn't, and Why? An
Experimental Study of the Mechanisms of Cultural Cognition”. Law and Human
Behavior. SSRN 1160654 12

* Lord, Charles G.; Lee Ross; Mark R. Lepper (1979). "Biased assimilation and
attitude polarization: The effects of prior theories on subsequently considered
evidence”. Joumal of Personality and Social Psychology. 37 (11): 2098-2109
CiteSeerX 10.1.1.372.1743@. doi:10.1037/0022-3514 37.11.2098.

ISSN 0022-3514 22

* HOVLAND, CARL |: WALTER WEISS (1951-12-21). "The Influence of Source
Credibility on Communication Effectiveness”. Public Opinion Quarterly. 15 (4):
635-650. doi:10.1086/266350 v2

«2 Braman, Donald: James Grimmelmann: Dan M. Kahan (20 July 2007).
"Modeling Cultural Cognition”. Social Justice Research. SSRN 10004492

* Fremling, G.M.; J.R. Lott Jr (2002). "Surprising Finding That Cultural
Worldviews Don't Explain People's Views on Gun Control, The” :2. U. Pa. L. Rev.
151 (4): 1341-1348. doi:10.2307/3312932 2. JSTOR 3312932

* Ayres, | Jd. Donohue ll (2002). Shooting down the more guns, less crime
hypothesis. National Bureau of Economic Research

* Lee, M.D.; M. Steyvers; M. de Young: B.J. Miller. "A Model-Based Approach to
Measuring Expertise in Ranking Tasks”

* Emst, Marc ©.; Martin S. Banks (2002-01-24). "Humans integrate visual and
haptic information in a statistically optimal fashion”. Nature. 415 (6870): 429-433
Bibcode:2002Natur.415..429E c2. doi:10.1038/415429a 2. ISSN 0028-0836 2
PMID 11807554.c2. S2CID 47459

* Wozny, D.R.; U.R. Beierholm; L. Shams (2008). "Human trimodal perception
follows optimal statistical inference” cz. Journal of Vision. 8 (3): 24.1-11
doi:10.1167/8.3.24@. PMID 18484830

* Brocas, Isabelle: Juan D. Carrillo (2012). "From perception to action: An
economic model of brain processes”. Games and Economic Behavior. 75: 81-103.
doi:10.1016/}.geb.2011.10.001 cz. ISSN 0899-8256 2